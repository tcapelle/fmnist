{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2017a4f2-3b18-4176-9fa8-e9f0fedbb156",
   "metadata": {},
   "source": [
    "# Getting started with TNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8645ca05-7d4d-4101-8efa-4427a82c776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from types import SimpleNamespace\n",
    "from typing import List, Tuple, Optional, Union, Any, Literal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "from torcheval.metrics import MulticlassAccuracy, Mean\n",
    "\n",
    "from torchtnt.framework import init_fit_state, State, fit, AutoUnit\n",
    "from torchtnt.utils import get_timer_summary, init_from_env, seed\n",
    "from torchtnt.utils.device import copy_data_to_device\n",
    "\n",
    "from wandb_logger import WandbLogger\n",
    "\n",
    "import timm\n",
    "\n",
    "_logger: logging.Logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "Batch = Tuple[torch.Tensor, torch.Tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1aca2855-90d0-42f1-b5e8-c90d79fd3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model_name:str, input_dim: int, device: torch.device) -> nn.Module:\n",
    "    model = timm.create_model(model_name, \n",
    "                              pretrained=False, \n",
    "                              num_classes=10, \n",
    "                              in_chans=input_dim)\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "887ec034-3632-4ac6-b365-4fc0e2fe71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(data_path:str, batch_size: int, num_workers: int) -> DataLoader:\n",
    "    \"\"\"Instantiate DataLoader\"\"\"\n",
    "    train_tfms = T.Compose([\n",
    "        T.RandomCrop(28, padding=1), \n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    val_tfms = T.Compose([\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    tfms = {\"train\": train_tfms, \"valid\":val_tfms}\n",
    "    train_ds = FashionMNIST(data_path, download=True, transform=tfms[\"train\"])\n",
    "    valid_ds = FashionMNIST(data_path, download=True, train=False, transform=tfms[\"valid\"])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                               pin_memory=True, num_workers=num_workers)\n",
    "    valid_dataloader = DataLoader(valid_ds, batch_size=batch_size*2, shuffle=False, \n",
    "                               num_workers=num_workers)\n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61d4b324-c369-482e-ba4f-fb9eff7c5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyUnit(AutoUnit[Batch]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        module: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        lr_scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "        device: Optional[torch.device],\n",
    "        log_frequency_steps: int = 10,\n",
    "        precision: Optional[Union[str, torch.dtype]] = None,\n",
    "        gradient_accumulation_steps: int = 1,\n",
    "        detect_anomaly: bool = False,\n",
    "        clip_grad_norm: Optional[float] = None,\n",
    "        clip_grad_value: Optional[float] = None,\n",
    "        use_wandb=False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            module=module,\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            device=device,\n",
    "            log_frequency_steps=log_frequency_steps,\n",
    "            precision=precision,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            detect_anomaly=detect_anomaly,\n",
    "            clip_grad_norm=clip_grad_norm,\n",
    "            clip_grad_value=clip_grad_value,\n",
    "        )\n",
    "        self.train_accuracy = MulticlassAccuracy(num_classes=10).to(device)\n",
    "        self.valid_accuracy = MulticlassAccuracy(num_classes=10).to(device)\n",
    "        self.train_loss = 0\n",
    "        self.valid_loss = Mean()\n",
    "        \n",
    "        self.use_wandb = use_wandb\n",
    "\n",
    "    # pyre-fixme[3]: See T137070928\n",
    "    def compute_loss(self, state: State, data: Batch) -> Tuple[torch.Tensor, Any]:\n",
    "        inputs, targets = data\n",
    "        outputs = self.module(inputs)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "\n",
    "        return loss, outputs\n",
    "\n",
    "    def update_metrics(\n",
    "        self,\n",
    "        state: State,\n",
    "        data: Batch,\n",
    "        loss: torch.Tensor,\n",
    "        outputs: Any,\n",
    "    ) -> None:\n",
    "        self.loss = loss\n",
    "        _, targets = data\n",
    "        self.train_accuracy.update(outputs, targets)\n",
    "\n",
    "    def log(self, d):\n",
    "        if self.use_wandb:\n",
    "            wandb.log(d)\n",
    "            \n",
    "    def log_metrics(\n",
    "        self, state: State, step: int, interval: Literal[\"step\", \"epoch\"]\n",
    "    ) -> None:\n",
    "        self.log({\"train_loss\": self.loss.item()})\n",
    "\n",
    "        accuracy = self.train_accuracy.compute()\n",
    "        self.log({\"train_accuracy\": accuracy})\n",
    "\n",
    "    def on_train_epoch_end(self, state: State) -> None:\n",
    "        super().on_train_epoch_end(state)\n",
    "        # reset the metric every epoch\n",
    "        self.train_accuracy.reset()\n",
    "        self.valid_accuracy.reset()\n",
    "        self.valid_loss.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03aad34-00be-4d2b-9bcd-eac1f4640d09",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fab0b5a-4100-41f2-9723-cc7e9a70618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    seed=42,\n",
    "    model_name=\"resnet10t\",\n",
    "    path=\".\",\n",
    "    input_dim=1,\n",
    "    lr=1e-3,\n",
    "    epochs=3,\n",
    "    batch_size=512,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f5acc50-27d6-49cf-9e82-540caf029116",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(config.seed)\n",
    "\n",
    "# device and process group initialization\n",
    "device = init_from_env()\n",
    "\n",
    "train_dl, valid_dl = prepare_dataloaders(config.path, config.batch_size, config.num_workers)\n",
    "\n",
    "module = prepare_model(config.model_name, config.input_dim, device)\n",
    "optimizer = AdamW(module.parameters(), lr=config.lr)\n",
    "lr_scheduler = OneCycleLR(optimizer, max_lr=config.lr, total_steps=config.epochs*len(train_dl))\n",
    "train_accuracy = MulticlassAccuracy(num_classes=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aa9014e-713a-4b4b-b553-8e61249fa829",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_unit = MyUnit(\n",
    "    module=module,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    device=device,\n",
    "    log_frequency_steps=10,\n",
    "    use_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df6ccb6e-fac6-4942-86c4-510d30dd6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = init_fit_state(\n",
    "        train_dataloader=train_dl,\n",
    "        eval_dataloader=valid_dl,\n",
    "        max_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae873f57-0bf8-4412-89af-e4c655174a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtnt.framework.fit:Started fit with max_epochs=3 max_steps=None max_train_steps_per_epoch=None max_eval_steps_per_epoch=None evaluate_every_n_steps=None evaluate_every_n_epochs=1 \n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n"
     ]
    }
   ],
   "source": [
    "fit(state, my_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265afd3-f197-49ab-846e-2ba36d426609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068939af-8f83-4e95-8ecb-a96ddf38177e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff749830-b382-47f9-91bb-e50e28506b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22d98b66-565e-43f9-8a89-421c35c36966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2yp61mo6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.86003</td></tr><tr><td>train_loss</td><td>0.41163</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">morning-wave-1</strong>: <a href=\"https://wandb.ai/capecape/tnt/runs/2yp61mo6\" target=\"_blank\">https://wandb.ai/capecape/tnt/runs/2yp61mo6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221230_165648-2yp61mo6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2yp61mo6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/fmnist/wandb/run-20221230_172237-3j8ba7kh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/tnt/runs/3j8ba7kh\" target=\"_blank\">quiet-breeze-2</a></strong> to <a href=\"https://wandb.ai/capecape/tnt\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"tnt\", entity=\"capecape\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eebfe3ff-da6e-47ad-a023-1304d9f8c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtnt.framework.fit:Started fit with max_epochs=3 max_steps=None max_train_steps_per_epoch=None max_eval_steps_per_epoch=None evaluate_every_n_steps=None evaluate_every_n_epochs=1 \n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n"
     ]
    }
   ],
   "source": [
    "fit(state, my_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6762d55-2ed2-40ef-a0a0-289660cc8e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▄▄▄▄▄▄▄▄▄▄▄▄▅▅▇▇▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>train_loss</td><td>▇██▇▇▇▆▄▆▄▆▆▄▅▄▆▄▄▄▄▃▄▄▄▃▂▃▃▃▃▃▁▃▄▂▂▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.832</td></tr><tr><td>train_loss</td><td>0.4602</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-breeze-2</strong>: <a href=\"https://wandb.ai/capecape/tnt/runs/3j8ba7kh\" target=\"_blank\">https://wandb.ai/capecape/tnt/runs/3j8ba7kh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221230_172237-3j8ba7kh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1772108-aa18-499e-b61b-1a4d55dc3b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/fmnist/wandb/run-20221230_165648-2yp61mo6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/tnt/runs/2yp61mo6\" target=\"_blank\">morning-wave-1</a></strong> to <a href=\"https://wandb.ai/capecape/tnt\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"tnt\", entity=\"capecape\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7005906-de09-48c3-ad4f-6fc0dfa97baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtnt.framework.train:Started train with max_epochs=10, max_steps=None, max_steps_per_epoch=None\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Started train epoch\n",
      "INFO:torchtnt.framework.train:Ended train epoch\n",
      "INFO:torchtnt.framework.train:Finished train\n"
     ]
    }
   ],
   "source": [
    "train(state, my_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04131-c9df-4bba-a876-55ac416b6971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
